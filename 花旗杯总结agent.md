## 总结板块的Agent的核心要求

生成经验-->该经验是为了修正模拟市场中的agent，使他们的行为和他们行为造成的价格走势都趋向于历史真实数据





## 模块输入



1. 输入的新闻
2. 分析板块对该新闻的分析-->情绪+行为趋势
3. 历史真实的对该新闻的分析-->情绪+行为趋势
4. 模拟市场板块数据
5. 真实的价格走势数据



## 模块输出

自然语言形式的文本



## 模块设计

我参考了reflexion的框架。以总结部分的视角看，整个项目可以分为三部分：

1. actor --> 新闻分析+市场模拟
2. evaluator --> 对模拟的结果打分
3. reflection -->对比模拟数据和真实数据，生成经验，用于指导下一次的模拟

### 评估模块

打分对象: 我们模拟出的市场价格曲线/新闻

打分规则: 模拟曲线和真实曲线夹起来的脱锚的面积差异，最大脱锚幅度差，脱锚面积比

​					新闻部分目前尚待细化



### 反思模块

![未命名绘图.drawio](D:\Download\未命名绘图.drawio.png)







简要流程-->

输入

评分

找到第一次超过阈值的点

若没有或者超过的分钟数小于某个值，说明拟合地很好

生成经验以强化得出该次市场曲线的经验，结束

若有

获取当前快照

与真实数据对比

指出在xx环境下执行xx动作会导致错误的后果

尝试修正，使用xx动作

使用大模型模拟推理/放入系统中再运行

评估修正动作的结果

存入经验，结束







```
流程：

市场和新闻分析板块生成模拟的评论和交易数据，并且判断出对该新闻的情绪

放入评分器中，评估这次模拟和真实数据的差异

if 模拟地较好 -->根据以往的经验模拟出的效果好

​	生成经验,强化正确逻辑
else

while 模拟地较差
	如果能够定位到市场中某个关键错误点-->定位到该错误点，修正
	若不能，则观察普遍模式，即整个市场的普遍情况普遍情绪，并修正

	(举例:输入某个新闻之后，模拟市场发生了恐慌性抛售，但是其在真实世界中仅引起了轻微的价格波动。说明agent对负面新闻过于敏感。生成提示词,适当降低对负面新闻的恐慌情绪)
	
	获取修正带来的预期结果
	如果跑一次模拟快，修正之后直接跑
	如果跑一次的时间慢，借助大模型的推理模拟能力获取模拟结果
	对修正结果重新进行评估
until 模拟地较好

return 语言经验反馈 即对于环境o_i
	对于失败的模拟
		推断出错误的行动a_i导致了后续的错误a_i+1和a_i+2-->可存入经验
		智能体表述其应该采取不同的行动a_i^`，-->模拟效果好则存入经验
	对于成功的模拟
		生成经验
		


```







经验样例：





**诊断出的失败模式**: 一次模拟中，美联储意外宣布大幅加息，真实世界的稳定币市场出现了短暂的、因流动性紧缩引发的脱锚。但模拟系统中的Agent们只关注与稳定币直接相关的新闻，完全忽略了这条宏观新闻，导致模拟价格毫无波澜。

**反思Agent生成的“行动准则” (自然语言文本):**

【历史复盘的关键教训】

重要指令：稳定币的韧性与宏观流动性息息相关。任何关于“央行利率”、“货币政策”、“系统性金融风险”的重大新闻，都必须被视为对稳定币市场的直接影响因素。

你必须分析此类宏观事件如何影响资金成本和市场流动性，并据此调整你的风险评估，即便新闻没有直接提及任何稳定币





评估板块实现：

新闻分析部分

​	分别总结真实市场和模拟市场的情绪，计算差异(待细化)

市场交易部分

​	设定阈值，依次扫描每个时间点，得出交易者的普遍情绪和当时的买卖趋势，第一个差异超过阈值的点则视为首个错误行动





### new block

首先根据评分器评价，得到本次模拟的得分 --> 得分是一个连续值

如果模拟得很好，那么不做处理

如果模拟效果不好，生成反思

带着反思重新模拟一次

如果本次模拟得分比上次高-->将这个反思存入经验中



(ps:如果单次模拟时间不长，可以考虑持续地反思模拟，直到我们认为模拟出的曲线足够好，即得分大于阈值K

初始化反思集

模拟出曲线

计算得分

while score<K do:

​	生成反思文本

​	带着该反思文本进行第i次模拟

​	如果第i次模拟比第i-1次模拟好

​	则奖励该反思文本

​	将被奖励的反思文本按照[反思文本,奖励数值]的方式存入反思集

(跳出循环，证明本次的模拟效果已经比较好)	

总结反思集得出经验/按照奖励数值降序选取前k个反思文本存入经验

)

经验存入数据库
